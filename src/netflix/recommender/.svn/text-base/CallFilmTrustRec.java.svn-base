package netflix.recommender;

//Debugging is twice as hard as writing the code in the first place. Therefore, 
//if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.

import java.text.DecimalFormat;
import netflix.FtMemreader.*;
import netflix.algorithms.memorybased.ftmemreader.FTMyRecommender;
import netflix.memreader.Sparsity;

public class CallFilmTrustRec

{

   	    String t; 
	    String tr;
	    String p; 
	    String f;
	    String storedt;
	    String storedtr;
	    String what;				
	    String fileNameToWrite;
	    
	    int 	myNeighbourSize;
	    int		myNeighbourInc;
	    String 	myType;				//type of recommender algo
	    double  factor;				//division factor train size
	    int 	topN;				//topN
	    Sparsity mySp;
	    FTMemHelper mhh;
	    double    ss;

	    boolean mySmallCall;
	    boolean mySparseCall;
	    boolean myTopCall;
	    int     myLoopIndex;
	    
	    
    public CallFilmTrustRec()
    
    {
    				//used to call some functions like calculate sparsity
    	
    }
	    
/*******************************************************************************************************/
    
 /**
 * @param small
 * @param sparseCall
 * @param top
 * @param topNumber
 * @param trainNumber
 * @param loopIndex
 * 
 */	    
	
   public CallFilmTrustRec(boolean small,			// small or large set
							boolean sparseCall,		// if sparse call, rather than simple data
							boolean top, 			// wanna see top users?
							int topNumber, 		    // how much training set (e.g.80) 
							int trainNumber,		// top N 
							int loopIndex)			//require to calculate the sparse results	
	{
	
		    mySp = new Sparsity();	
		
			myNeighbourSize = 500;
			myNeighbourInc  = 100;
			factor			= (trainNumber * (1.0))/100.0;
			topN			= topNumber;
			//myType			= "simple";
		    //myType			= "deviation";
			

			 mySmallCall 		= small;
		     mySparseCall 		= sparseCall;
		     myTopCall 			= top;
		     myLoopIndex 		= loopIndex;
	}
	
		    
/*******************************************************************************************************/
	
	    public void callsetUpFunction	    
	    				(boolean small,			// small or large set
						 String  whichCall,		// Contains sparse etc
	    				 int topNumber, 		// how much training set (e.g.80) 
						 int trainNumber,		// top N 
						 int loopIndex,      	// require to calculate the sparse results
						 int factorX			// to determine which of the test-train ratio is there
	    				)		

 {			factor			= (trainNumber * (1.0))/100.0;
			topN			= topNumber;
			//myType			= "LOO";
			
		//	myType		= "deviation";

			
		if (small ==true)
			
		{
					
						//All users
			//10-90
			//20-80
			//30-70
			
		
			
			//all, non-sparse, cross
		if (whichCall.equalsIgnoreCase("AllNonSparseCrossNeighbour")) //here we will check cross validation
				 
			  {
				String neighbourz = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\Neighbourhood\\";
				// p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\TenFoldData\\";
				 p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\FiveFoldData\\";
				f = p + "sml_storedRatings.dat";
				
				    
			  //  t  		 = p + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
		       // tr 		 = p + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
				
				 //we have everything in the folder we just need to call recommender function with suitable names
				storedt	 = p + "DataR1\\"+ "ft_testSetStoredFold" + loopIndex + ".dat";			
				storedtr = p + "DataR1\\"+ "ft_trainSetStoredFold" + loopIndex + ".dat";
				what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
//				fileNameToWrite = neighbourz + "\\Results\\" + myType + "Fold" + loopIndex;
				fileNameToWrite = p + "\\ResultsR1\\" + myType + "Fold" + loopIndex;
			 }
			
		
		//top, non-sparse, cross
		if (whichCall.equalsIgnoreCase("TopNonSparseCrossNeighbour")) //here we will check cross validation
				 
			  {
				String neighbourz = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\Neighbourhood\\";
				// p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\TenFoldData\\";
				 p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\FiveFoldData\\";
				f = p + "sml_10StoredRatings.dat";
				
				    
			  //  t  		 = p + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
		       // tr 		 = p + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
				
				 //we have everything in the folder we just need to call recommender function with suitable names
				storedt	 = p + "DataR10\\"+ "ft_testSetStoredFold" + loopIndex + ".dat";			
				storedtr = p + "DataR10\\"+ "ft_trainSetStoredFold" + loopIndex + ".dat";
				what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
//				fileNameToWrite = neighbourz + "\\Results\\" + myType + "Fold" + loopIndex;
				fileNameToWrite = p + "\\ResultsR10\\" + myType + "Fold" + loopIndex;
			 }
			
			
		//just to check if this is working fine for ML?
		if (whichCall.equalsIgnoreCase("MLTopNonSparseCrossNeighbour")) //here we will check cross validation
			 
		  {
			String neighbourz = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\Neighbourhood\\";
			// p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\TenFoldData\\";
			 p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\FiveFoldData\\";
			f = p + "sml_storedRatings.dat";
			
			    
		  //  t  		 = p + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	       // tr 		 = p + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 = p + "DataM1\\"+ "ft_testSetStoredFold" + loopIndex + ".dat";			
			storedtr = p + "DataM1\\"+ "ft_trainSetStoredFold" + loopIndex + ".dat";
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
//			fileNameToWrite = neighbourz + "\\Results\\" + myType + "Fold" + loopIndex;
			fileNameToWrite = p + "\\ResultsM1\\" + myType + "Fold" + loopIndex;
		 }
		
	
		
		if (whichCall.equalsIgnoreCase("AllNonSparseNeighbour")) 
		 
		  {
		
			 p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\Neighbourhood\\";
			 f = p + "sml_storedRatings.dat";
			
			    
		    t  		 = p + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 = p + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
			storedt	 = p + "\\WrittenFiles\\"+"sml_testSetStoredAll" + "_" + (100-trainNumber) + ".dat";			
			storedtr = p + "\\WrittenFiles\\"+"sml_trainSetStoredAll" + "_" + trainNumber + ".dat";
			what 	 ="ALL sml with " + trainNumber + " train and " + (100-trainNumber) +" test data";
			fileNameToWrite = p + "\\Results\\" + myType + "All" + "_" + trainNumber + ".dat";
		 }
		  
		if (whichCall.equalsIgnoreCase("AllSparse"))	//now we will play with sparse data
			
		  {
			    p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\Sparsity\\";
				f = p + "sml_storedRatings.dat";
								    
	//		    t  		 = p + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	//	        tr 		 = p + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
				storedt	 = p + "\\WrittenFiles\\"+"sml_testSetStoredaAll" + "_" + (100-trainNumber) + ".dat";
				
				storedtr = p + "\\WrittenFiles\\"+"sml_trainSetStoredAll" + "_" + (trainNumber) + "_" + (loopIndex) + ".dat";
				what 	 ="ALL sml with " + trainNumber + " train and " + (100-trainNumber) +" test data" + " 10% sparsity";
				mhh= new FTMemHelper(storedtr);
			//	ss = mySp.calculateSparsity(mhh);
				fileNameToWrite = p + "\\Results\\" +  myType + "All" + "_" + trainNumber + "_" + ss ;
			  
			  			  
		  }
		 
	   
		
		if (whichCall.equalsIgnoreCase("AllSimpleCheck")) //here we will chcek simple rmse, user and movie average
     	  {
	
			p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\SimpleCheck\\";
			f = p + "ft_storedRatings.dat";
			
			
			    
		    t  		 =  p + "Data1\\" + "ft_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 =  p + "Data1\\" + "ft_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 =  p + "Data1\\"+ "ft_testSetStored" + trainNumber + ".dat";			
			storedtr =  p + "Data1\\"+ "ft_trainSetStored" + trainNumber + ".dat";
			
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
			fileNameToWrite = p + "\\Results1\\" + myType ;
		 }
	
	
	
		if (whichCall.equalsIgnoreCase("AllSimpleCheckLOO")) //here we will chcek simple rmse, user and movie average
   	  {
	
			p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\SimpleCheck\\";
			f = p + "ft_storedRatings.dat";
			
			
			    
		    t  		 =  p + "Data1\\" + "ft_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 =  p + "Data1\\" + "ft_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 =  f;			
			storedtr =  f;
			
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
			fileNameToWrite = p + "\\Results1\\" + myType ;
		 }
	
	

		if (whichCall.equalsIgnoreCase("604AllSimpleCheckLOO")) //here we will chcek simple rmse, user and movie average
   	  {
	
			p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\SimpleCheck\\";
			f = p + "ft_604storedRatings.dat";
			
			
			    
		    t  		 =  p + "Data1\\" + "ft_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 =  p + "Data1\\" + "ft_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 =  f;			
			storedtr =  f;
			
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
			fileNameToWrite = p + "\\Results1\\" + myType ;
		 }
	
		if (whichCall.equalsIgnoreCase("AllSimpleCheckKFold")) //here we will chcek simple rmse, user and movie average
	   	  {
		
				p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\FiveFoldData\\";
				f = p + "ft_storedRatings.dat";
				
				
				    
			    t  		 =  p + "Data1\\" + "ft_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
		        tr 		 =  p + "Data1\\" + "ft_trainSetAll.dat" + "_" + trainNumber + ".dat";
				
				 //we have everything in the folder we just need to call recommender function with suitable names
				storedt	 =  f;			
				storedtr =  f;
				
				what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
				fileNameToWrite = p + "\\Results1\\" + myType ;
			 }
		
		
		
		if (whichCall.equalsIgnoreCase("MLAllSimpleCheckLOO")) //here we will chcek simple rmse, user and movie average
   	    {
	
			p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\SimpleCheck\\";
			f = p + "sml_storedRatings.dat";
			
			
			    
		    t  		 =  p + "DataM1\\" + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 =  p + "DataM1\\" + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 =  f;			
			storedtr =  f;
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
			fileNameToWrite = p + "\\ResultsM1\\" + myType ;
		 }
	
	
		if (whichCall.equalsIgnoreCase("MLAllSimpleCheckKFold")) //here we will chcek simple rmse, user and movie average
   	    {
	
			p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\FiveFoldData\\";
			f = p + "sml_storedRatings.dat";
			
			
			    
		    t  		 =  p + "DataM1\\" + "sml_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 =  p + "DataM1\\" + "sml_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 =  f;			
			storedtr =  f;
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
			fileNameToWrite = p + "\\ResultsM1\\" + myType ;
		 }
	
		
		
		
		if (whichCall.equalsIgnoreCase("TopSimpleCheck")) //here we will chcek simple rmse, user and movie average
   	  {
	
			p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\FT\\TestTrain\\SimpleCheck\\";
			//f = p + "ft_storedRatings.dat";
			f = p + "\\Data51\\ft_5StoredRatings.dat";
			
			    
		    t  		 =  p + "Data51\\" + "ft_testSetAll.dat"+ "_" + (100-trainNumber) + ".dat";;
	        tr 		 =  p + "Data51\\" + "ft_trainSetAll.dat" + "_" + trainNumber + ".dat";
			
			 //we have everything in the folder we just need to call recommender function with suitable names
			storedt	 =  p + "Data51\\"+ "ft_testSetStored" + trainNumber + ".dat";			
			storedtr =  p + "Data51\\"+ "ft_trainSetStored" + trainNumber + ".dat";
			what 	 ="ALL sml with  10 fold cross validation in 80% of traing set for checking parameter sensitivity";
			fileNameToWrite = p + "\\Results51\\" + myType ;
		 }
		
		//users who saw > N movies
		//10-90
		//20-80
		//30-70
		
		if (whichCall.equalsIgnoreCase("TopNonSparse"))
			
			{
			
				p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\TestTrain\\";
				f = p + "sml_storedRatings" + topNumber + ".dat";
			
			
				t  		 = p + "sml_testSetTop" + topNumber + "_" + (100-trainNumber) + ".dat";
				tr 		 = p + "sml_trainSetTop" + topNumber +  "_" + trainNumber + ".dat";
				
				storedt	 = p + "\\WrittenFiles\\" + "sml_testSetStoredTop" + topNumber + "_" + (100-trainNumber) + ".dat";
				storedtr = p + "\\WrittenFiles\\"+ "sml_trainSetStoredTop" + topNumber + "_" + trainNumber + ".dat";
				what 	 ="Top"  + topNumber +  "sml with " + trainNumber + " train and " + (100-trainNumber) +" test data";
				fileNameToWrite = p + "\\Results\\"+ myType + topNumber + "_" + trainNumber + ".dat";
			} 
			
		if (whichCall.equalsIgnoreCase("TopSparse")) 	//it is a sparse call with top 20 movies
			
			{
				p = "C:\\Users\\Musi\\workspace\\MusiRecommender\\DataSets\\SML_ML\\Sparsity\\";
				f = p + "sml_storedRatings" + topNumber + ".dat";
			
			
				t  		 = p + "sml_testSetTop" + topNumber + "_" + (100-trainNumber) + ".dat";
				tr 		 = p + "sml_trainSetTop" + topNumber +  "_" + trainNumber + ".dat";
				storedt	 = p + "\\WrittenFiles\\"+"sml_testSetStoredTop" + topNumber + "_" + (100-trainNumber) + ".dat";
				
				//this should change in every step
				storedtr = p + "\\WrittenFiles\\" + "sml_trainSetStoredTop" + topNumber + "_" + trainNumber + "_" + (loopIndex *10) + ".dat";
				what 	 ="Top"  + topNumber +  "sml with " + trainNumber + " train and " + (100-trainNumber) +" test data" + (loopIndex*10) + "% Sparsity"; 
				mhh= new FTMemHelper(storedtr);
		//		ss = mySp.calculateSparsity(mhh); 
				fileNameToWrite = p + "\\Results\\" + myType + topNumber + "_" + trainNumber + "_" + ss + ".dat";
			
				
			}
		

	}//end of small
		
				    
	}
	
	
/******************************************************************************************/
	
	public static void main (String arg[])
	
	{
	
		boolean smallCall	=true;
		boolean sparseCall	=false;
		boolean topCall  	=false;
		boolean crossCall  	=false;
		
		String myCallChoice ="";
		
		int topNo	 		=20;		
		int train			=80;		//by default for sparsity we are making 20-80%
		double sparseWrite  =0.0;
		
		//I am considering only small set and topset with top20
		
		CallFilmTrustRec rrr = new CallFilmTrustRec();
		
		
		CallFilmTrustRec cr = new CallFilmTrustRec(smallCall,
													sparseCall,
													topCall,
													topNo,
													train,
													0
													);
		
		
	      //_____________________________________________________________________
	     // make a sparse call 
		 //_____________________________________________________________________
		
		
 /*			myCallChoice = "AllSparse";
 			train= 80;
							
				   for (int j = 0; j<100; j+=10) // train size = 90,80,70 ...
				
					
					{
											
						 cr.callsetUpFunction ( smallCall,		// sml_dataset
												myCallChoice,	// which type of data set to call and parameter to check for
												topNo,			// top20 or all
												train,			// 80
												j,				// loop index for sparse
												0				// for checking test train ratio
						 					  );
			
						cr.call();
					
					}

				
			
	*/		//_____________________________________________________________________
		     // 
			 //_____________________________________________________________________
			
			
			
	/*		else	//now we will simply play with sparse data (THis is called once) 
			  
			 {
				 for (int j = 1; j <10; j++) //there are 9 sparse dataset against each (i.e. all, and top20) 
				 
				 {	 
					    					 
					 cr.callsetUpFunction ( smallCall,
											sparseCall,
											topCall,
											crossCall,
											topNo,
											train,
											j 
										  );

						cr.call();
				 }
				 
			  }//end of sparse call
		*/		
			//_____________________________________________________________________
		     // corss validation with data set 20 test and 80 train 
			 // train is further divided into 10- fold corss validation
			 // to check up for paramter sensitivity
			 //_____________________________________________________________________
			
		
	/*	myCallChoice = "AllNonSparseNeighbour";
		
		for (int i=0; i<9; i++)				// for factor x (test train ration) x=0.1 means 10% test set
		{
		 for (int j = 0; j <10; j++)      //there are 10 folds 
			 
		 {	 
			    					 
			 cr.callsetUpFunction ( smallCall,
									myCallChoice,
					 				topNo,
									train,
									j+1,
									i+1
								  );

				cr.call();
		 }
		 
		}
		
		*/

		//_____________________________________________________________________
	     // 5- fold corss validation with data set 20 test and 80 trian 
		 // for neighbour hood size
		 //
		 //_____________________________________________________________________

	/*	int howMuchFolds =5;
		myCallChoice = "TopNonSparseCrossNeighbour";
		smallCall =true;
		
		 for (int j = 0; j <howMuchFolds; j++)      //there are 10 folds 
			 
		 {	 
			    					 
			 cr.callsetUpFunction ( smallCall,		// sml_dataset
									myCallChoice,	// which type of data set to call and parameter to check for
					 				topNo,			// top20 or all
									train,			// 80
									j+1,			// fold index
									0				//used for sparsity cal
								  );

				cr.call();
		 }
	
	*/
		

		//_____________________________________________________________________
	     // 5- fold corss validation with data set 20 test and 80 trian 
		 // for neighbour hood size.... ML
		 //
		 //_____________________________________________________________________
/*
		int howMuchFolds =5;
		myCallChoice = "MLTopNonSparseCrossNeighbour";
		smallCall =true;
		
		 for (int j = 0; j <howMuchFolds; j++)      //there are 10 folds 
			 
		 {	 
			    					 
			 cr.callsetUpFunction ( smallCall,		// sml_dataset
									myCallChoice,	// which type of data set to call and parameter to check for
					 				topNo,			// top20 or all
									train,			// 80
									j+1,			// fold index
									0				//used for sparsity cal
								  );

				cr.call();
		 }
	
	*/
	   //_____________________________________________________________________
	     // 
		 // Just to check why user and movie average is going good than that of 
		 // predicited?
		 //_____________________________________________________________________
	

    	 
    	// myCallChoice = "AllSimpleCheckKFold";
    	// myCallChoice = "MLAllSimpleCheckLOO";
		// myCallChoice = "MLAllSimpleCheckKFold";
		  
	        myCallChoice = "604AllSimpleCheckLOO";
	//         myCallChoice = "AllSimpleCheckLOO";
		
    //	cr.myType			= "KFold";
    	cr.myType			= "LOO";
		
		smallCall = true;
		train = 80;
		
		{
			
			
		 cr.callsetUpFunction ( smallCall,		// sml_dataset
								myCallChoice,	// which type of data set to call and parameter to check for
				 				topNo,			// top20 or all
								train,			// 80
								0,				// fold index
								0				//used for sparsity cal
							  );

			cr.call();
		}


		//_____________________________________________________________________
	     // 
		 // If program is working fine for ML? yes 
		 //
		 //_____________________________________________________________________
		
	/*	
		myCallChoice = "MLAllSimpleCheckLOO";
		smallCall = true;
		train = 80;
		
		{
			
			
		 cr.callsetUpFunction ( smallCall,		// sml_dataset
								myCallChoice,	// which type of data set to call and parameter to check for
				 				topNo,			// top20 or all
								train,			// 80
								0,				// fold index
								0				//used for sparsity cal
							  );

			cr.call();
		}
*/
	
		
	}//end of main
	
	
/******************************************************************************************/
	
	public void call()	
	{
		
		//objects of related classes
		FTDivideIntoSets div 			= new FTDivideIntoSets();
		//SimpleDivideIntoSets Sdiv 	= new SimpleDivideIntoSets();
		FTMemReader       mr		    = new FTMemReader ();
		FTMyRecommender   myRec 		= new FTMyRecommender();
	//	AnalyzeAFile    ana			= new AnalyzeAFile();
		
		double sparse =0.0;
			
	
/*		// divide main file into test and train file
		div.divideIntoTestTrain(f,							// main object already there
								tr, 						// training object to be written	
								t, 							// test object to be written	
								factor); 					// train-test propotion factor
		
	//	Sdiv.divideIntoTestTrain(f, tr, t, 0.8); 			//wtf....good results
		System.out.println("Done division");
	
		
		mr.writeIntoDisk(t, storedt); 							//write test set into memory
		mr.writeIntoDisk(tr, storedtr);							//write train set into memory
				
	//	ana.analyzeContent(storedtr);							//analyze the content of training object	
		//sparse = ana.calculateSparsity(storedtr);				//calculate sparsity level
		
		System.out.println("Done writing");
*/

	
		
		
/*
		myRec.makeCorrPrediction(storedtr,		 //training set object 
				storedt, 						 //test set object
				p, 								 //path where these objects are present
				what + ", Sparsity = "+ sparse,  //information about training set
				false, 							 //write Roc related results into the file?
				false,							 //write REComendation related results into the file?
				myType,							 //"simple", "deviation"
				myNeighbourSize,
				myNeighbourInc
				);		

	*/	
		
	myRec.makeCorrPrediction  (storedtr,						 //training set object 
							   storedt, 						 //test set object
								p, 								 //path where these objects are present
								what + ", Sparsity = "+ sparse,  //information about training set
								false, 							 //write Roc related results into the file?
								true,							 //write REComendation related results into the file?
								myType,							 //"simple", "deviation"
								fileNameToWrite,				 //write results in this file
								myNeighbourSize,
								myNeighbourInc
								);		
			
		
	}
	
/*****************************************************************************************************/
	
	
	
}
